---
title: "Hello!"
layout: single
permalink: /
---

I'm a 3rd year PhD candidate in Computer Science at the [University of Washington](https://www.cs.washington.edu/), and a visiting researcher at [Facebook AI Research](https://ai.facebook.com/). I'm advised by [Noah Smith](https://nasmith.github.io/) and [Luke Zettlemoyer](https://www.cs.washington.edu/people/faculty/lsz).

I was previously a Predoctoral Young Investigator at [AI2](http://allenai.org), and a data scientist and software engineer in startups in Boston and Seattle. And in another world, I did research in [neuroscience](#neuroscience)!

These days, I'm excited about developing  models that are [modular](https://www.semanticscholar.org/paper/DEMix-Layers%3A-Disentangling-Domains-for-Modular-Gururangan-Lewis/917c63f2186119166b3379f5d2816bb1a2f39b09) and [embarrassingly parallel](https://www.semanticscholar.org/paper/Branch-Train-Merge%3A-Embarrassingly-Parallel-of-Li-Gururangan/8b3a67c7e5289eed160d2acfd04d71cfb552c67d). Much of my research investigates [language](https://www.semanticscholar.org/paper/RealToxicityPrompts%3A-Evaluating-Neural-Toxic-in-Gehman-Gururangan/399e7d8129c60818ee208f236c8dda17e876d21f) [variation](https://www.semanticscholar.org/paper/Time-Waits-for-No-One!-Analysis-and-Challenges-of-Luu-Khashabi/17d7fd18123e12efbb9c255c8b986a5e84578b07) in [large](https://www.semanticscholar.org/paper/Don%E2%80%99t-Stop-Pretraining%3A-Adapt-Language-Models-to-Gururangan-Marasovi%C4%87/e816f788767eec6a8ef0ea9eddd0e902435d4271) [datasets](https://www.semanticscholar.org/paper/Whose-Language-Counts-as-High-Quality-Measuring-in-Gururangan-Card/0a4b8b161931799d5c6bc3ecf07c53bae0e9e502), and how the composition of training data affects  the overall behavior of language models. I strongly believe that being careful about our data will lead to stronger and more reliable language technologies.


I have co-authored papers that were cited as "outstanding" and "honorable mention for best paper" at [ACL 2020](https://aclanthology.org/2020.acl-main.740/) and [ACL 2021](https://aclanthology.org/2021.acl-long.565/).


Check out my [publications](https://suchin.io/publications/) to learn more.

## Announcements
* Oct 2022: Three papers ("Whose Language Counts as High Quality", "M2D2", and "Nearest Neighbor Zero-Shot Inference") accepted to EMNLP 2022!
* Sept 2022: Talk at USC
* Aug 2022: Talk at Mosaic ML, on "Branch-Train-Merge"
* Aug 2022: Our new paper ["Branch-Train-Merge"](https://arxiv.org/abs/2208.03306) just dropped!
* June 2022: Our new paper ["Nearest Neighbor Zero-Shot Inference"](https://suchin.io/assets/knnprompt.pdf) is live!
* March 2022: Two papers ("DEMix" and "Time Waits for No One!") accepted to NAACL 2022!
* March 2022: Talk at IBM Research Zurich.
* April 2022: I'll be giving a guest lecture in the **Data Processing + Values** course at UW on our [quality filtering](https://arxiv.org/abs/2201.10474) paper.
* January 2022: Our new preprint, ["Whose Language Counts As High Quality?"](https://arxiv.org/abs/2201.10474), just dropped!
